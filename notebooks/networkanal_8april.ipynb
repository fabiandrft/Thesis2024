{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2bd6e30d-ab4b-42d6-959d-20fbe8fbdfcd",
   "metadata": {},
   "source": [
    "### open csv and inspect data\n",
    "\n",
    "0 load old file without time cutoff point; create df_network as a copy of df_network which only has channel_name, links, channel_category, and datetime; set media = movement\n",
    "\n",
    "1 when first official party chat? \n",
    "\n",
    "2 visualise party messages over time\n",
    "\n",
    "3 segment dataset to see how it evolves over time and see how centrality and degree of party chats change\n",
    "    \n",
    "\n",
    "4 create set with and without party\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf394358-085d-469c-891f-477ee99ec29e",
   "metadata": {},
   "source": [
    "### step 0: create df_network and edgelist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0358057-fd36-4074-a6df-76af60591009",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"output_final_t5.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c252d1-0f0a-457a-b175-3389d75fdb34",
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicates = df.duplicated(subset='link_to_message', keep=False)\n",
    "\n",
    "# Counting the number of duplicates\n",
    "number_of_duplicates = duplicates.sum()\n",
    "\n",
    "# Printing the number of duplicates\n",
    "print(f\"Number of duplicate entries in 'link_to_message': {number_of_duplicates}\")\n",
    "df = df.drop_duplicates(subset= \"link_to_message\", keep='first')\n",
    "duplicates = df.duplicated(subset='link_to_message', keep=False)\n",
    "\n",
    "# Counting the number of duplicates\n",
    "number_of_duplicates = duplicates.sum()\n",
    "\n",
    "# Printing the number of duplicates\n",
    "print(f\"Number of duplicate entries in 'link_to_message': {number_of_duplicates}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ac637c-2377-4a7a-861d-df93289fa61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "na_count = df['text'].isna().sum()\n",
    "print(f\"Number of rows with NA in 'text' column: {na_count}\")\n",
    "\n",
    "# Remove rows where 'text' is NA\n",
    "df = df.dropna(subset=['text']).copy()\n",
    "\n",
    "# Verify removal\n",
    "print(f\"Number of rows after removing NAs: {len(df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04e4507-a2c5-4335-bb21-85a3e56cd1a2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['channel_category'] = 0\n",
    "\n",
    "# Function to categorize channel based on 'channel_name'\n",
    "def categorize_channel(channel_name):\n",
    "    channel_name_lower = channel_name.lower()\n",
    "    if 'basis' in channel_name_lower:\n",
    "        return 'party'\n",
    "    return 'movement'  # Return 'movement'\n",
    "\n",
    "# Apply the categorization function to the 'channel_name' column\n",
    "df['channel_category'] = df['channel_name'].apply(categorize_channel)\n",
    "\n",
    "# Display the DataFrame to verify the new 'channel_category' column\n",
    "print(df)\n",
    "df_network = df[['channel_name', 'links', 'channel_category', 'datetime']].copy()\n",
    "df_network['datetime'] = pd.to_datetime(df_network['datetime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d677f4-8f54-434f-8f06-38e9c9c625fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_network['channel_category'] = df_network['channel_category'].replace('media', 'movement')\n",
    "df_network['channel_category'] = df_network['channel_category'].replace('0', 'movement')\n",
    "df_network['channel_category'] = df_network['channel_category'].replace(0, 'movement')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b36f9fa-fbab-4104-8d78-1e12da7d99f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_network['channel_category'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20512fea-9d21-41a3-a119-4c0088dace81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def extract_valid_telegram_username(link_text):\n",
    "    # Ensure input is a string\n",
    "    if not isinstance(link_text, str):\n",
    "        return None\n",
    "    # Define the pattern for extracting Telegram usernames\n",
    "    telegram_pattern = re.compile(r'(?:https?://)?t\\.me/([\\w\\d_-]+)')\n",
    "    # Search for all occurrences of the pattern\n",
    "    matches = telegram_pattern.findall(link_text)\n",
    "    # Filter out any non-Telegram links or invalid entries\n",
    "    valid_usernames = [match for match in matches if not any(ext in match for ext in ['http', 'https', '|'])]\n",
    "    # Return the first valid Telegram username, if available\n",
    "    return valid_usernames[0] if valid_usernames else None\n",
    "\n",
    "# Apply the refined function to extract valid Telegram usernames\n",
    "df_network['links'] = df_network['links'].apply(extract_valid_telegram_username)\n",
    "df_network['links'] = df_network['links'].str.lower()\n",
    "\n",
    "# Drop rows without a valid Telegram username\n",
    "df_network = df_network.dropna(subset=['links'])\n",
    "df_network = df_network.dropna(subset=['channel_name'])\n",
    "df_network = df_network.dropna(subset=['channel_category'])\n",
    "\n",
    "contains_floats = df_network['links'].apply(lambda x: isinstance(x, float)).any()\n",
    "\n",
    "if contains_floats:\n",
    "    print(\"The column contains float values.\")\n",
    "    df_network = df_network[~df_network['links'].apply(lambda x: isinstance(x, float))]\n",
    "else:\n",
    "    print(\"No float values in 'links'.\")\n",
    "\n",
    "# create edgelist for copy\n",
    "edgelist = df_network.copy()\n",
    "edgelist['source'] = edgelist['channel_name'].str.lower()\n",
    "edgelist['target'] = edgelist['links'].str.lower()\n",
    "edgelist['channel_category'] = edgelist['channel_category'].str.lower()\n",
    "\n",
    "edgelist = edgelist.drop('channel_name', axis=1)\n",
    "edgelist = edgelist.drop('links', axis=1)\n",
    "# Display the first few rows of edgelist to verify\n",
    "print(edgelist.head())\n",
    "len(edgelist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "847b7425-7313-4bcc-8004-5322d7d43624",
   "metadata": {},
   "source": [
    "### step 1: visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e88d82-db54-4319-885b-86a7e3f30f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "\n",
    "# Assuming 'df_network' is your DataFrame\n",
    "# Convert 'datetime' to datetime format (if it's not already)\n",
    "edgelist['datetime'] = pd.to_datetime(edgelist['datetime'])\n",
    "\n",
    "# Set 'datetime' as the DataFrame index\n",
    "if 'datetime' in edgelist.columns:\n",
    "    edgelist['datetime'] = pd.to_datetime(edgelist['datetime'])\n",
    "    edgelist.set_index('datetime', inplace=True)\n",
    "elif not isinstance(edgelist.index, pd.DatetimeIndex):\n",
    "    # If 'datetime' is not a column and the index is not a DatetimeIndex, there might be an issue\n",
    "    raise ValueError(\"The DataFrame does not have a 'datetime' column or datetime index.\")\n",
    "\n",
    "\n",
    "# Resample by month and count occurrences\n",
    "# a) Sum of 'basis' in source and target\n",
    "edgelist['basis_in_source'] = edgelist.apply(lambda x: 'basis' in x['source'] if isinstance(x['source'], str) else False, axis=1)\n",
    "edgelist['basis_in_target'] = edgelist.apply(lambda x: 'basis' in x['target'] if isinstance(x['target'], str) else False, axis=1)\n",
    "edgelist_monthly_basis = edgelist.resample('ME').sum()\n",
    "\n",
    "# b) Only in source\n",
    "edgelist_monthly_source = edgelist[edgelist['channel_category'] == 'party'].resample('ME').count()\n",
    "\n",
    "# c) Only in target - assuming direct text match, adjust for regex if needed\n",
    "edgelist_monthly_target = edgelist[edgelist['basis_in_target']].resample('ME').count()\n",
    "\n",
    "# Total volume of edges per month\n",
    "edgelist_monthly_total = edgelist.resample('ME').count()\n",
    "\n",
    "# Combine into a single DataFrame\n",
    "edgelist_combined = pd.DataFrame({\n",
    "    'Party Source+Target': edgelist_monthly_basis['basis_in_source'] + edgelist_monthly_basis['basis_in_target'],\n",
    "    'Party Chat Source': edgelist_monthly_source['source'],\n",
    "    'Party Chat target': edgelist_monthly_target['target'],\n",
    "    'Total Volume': edgelist_monthly_total['source']  # or any column that exists for every row\n",
    "})\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 6))\n",
    "edgelist_combined.plot(kind='line', ax=plt.gca())\n",
    "plt.title('Monthly \"Basis\" Mentions and Total Volume of Edges')\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Count')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "\n",
    "# Print the earliest mention of \"basis\"\n",
    "earliest_basis = edgelist[edgelist['basis_in_source'] | edgelist['basis_in_target']].index.min()\n",
    "print(f\"Earliest mention of 'basis': {earliest_basis}\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64545246-60d3-454c-98d0-d721ccc1788b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "\n",
    "\n",
    "# Plotting for left axis\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "for column in ['Party Source+Target', 'Party Chat Source', 'Party Chat target']:\n",
    "    ax.plot(edgelist_combined.index, edgelist_combined[column], marker='o', label=column)\n",
    "\n",
    "ax.set_title('Monthly \"Basis\" Mentions and Total Volume of Edges')\n",
    "ax.set_xlabel('Month')\n",
    "ax.set_ylabel('Count (Party Chats)', color='tab:blue')\n",
    "ax.tick_params(axis='y', labelcolor='tab:blue')\n",
    "ax.grid(True)\n",
    "ax.set_ylim(None, 1000)  # Automatically adjust the lower limit, set the upper limit to 1000\n",
    "\n",
    "#second x axis\n",
    "ax2 = ax.twinx()\n",
    "ax2.plot(edgelist_combined.index, edgelist_combined['Total Volume'], color='tab:grey', marker='x', label='Total Volume')\n",
    "ax2.set_ylabel('Total Volume', color='tab:grey')  \n",
    "ax2.tick_params(axis='y', labelcolor='tab:grey')\n",
    "\n",
    "lines, labels = ax.get_legend_handles_labels()\n",
    "lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "ax.legend(lines + lines2, labels + labels2, loc='upper left')\n",
    "\n",
    "earliest_basis = edgelist[edgelist['basis_in_source'] | edgelist['basis_in_target']].index.min()\n",
    "print(f\"Earliest mention of 'basis': {earliest_basis}\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d74c58a-24fd-4647-93a7-815f51af3b9b",
   "metadata": {},
   "source": [
    "### step 2: inspect splitting purposefulness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affaa657-8601-4162-af8e-f903e18958f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Ensure datetime is in the correct format and set as index\n",
    "\n",
    "# Define the split point\n",
    "split_point = pd.Timestamp('2020-06-26 07:29:18+00:00', tz='UTC')\n",
    "\n",
    "# Split data into before and after the split point\n",
    "before = edgelist[edgelist.index < split_point]\n",
    "after = edgelist[edgelist.index >= split_point]\n",
    "\n",
    "# Count edges in each period\n",
    "edges_before = before.shape[0]\n",
    "edges_after = after.shape[0]\n",
    "\n",
    "# Identify unique nodes\n",
    "nodes_before = pd.unique(before[['source', 'target']].values.ravel('K'))\n",
    "nodes_after = pd.unique(after[['source', 'target']].values.ravel('K'))\n",
    "\n",
    "# Count unique nodes\n",
    "unique_nodes_before = len(nodes_before)\n",
    "unique_nodes_after = len(nodes_after)\n",
    "\n",
    "# Calculate time periods lengths in days\n",
    "period_before_days = (split_point - edgelist.index.min()).days\n",
    "period_after_days = (edgelist.index.max() - split_point).days\n",
    "\n",
    "# Weight counts by period length\n",
    "edges_before_weighted = edges_before / period_before_days\n",
    "edges_after_weighted = edges_after / period_after_days\n",
    "nodes_before_weighted = unique_nodes_before / period_before_days\n",
    "nodes_after_weighted = unique_nodes_after / period_after_days\n",
    "\n",
    "# Weight counts by period length and print with explanations\n",
    "print(f\"Edges before 2020-06-26: {edges_before} (weighted by time: {edges_before_weighted:.2f} edges/day)\")\n",
    "print(f\"Edges after 2020-06-26: {edges_after} (weighted by time: {edges_after_weighted:.2f} edges/day)\")\n",
    "print(f\"Unique nodes before 2020-06-26: {unique_nodes_before} (weighted by time: {nodes_before_weighted:.2f} nodes/day)\")\n",
    "print(f\"Unique nodes after 2020-06-26: {unique_nodes_after} (weighted by time: {nodes_after_weighted:.2f} nodes/day)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011ca839-f37a-4268-9ff1-00b6ec1b858b",
   "metadata": {},
   "source": [
    "### step 3: segment network based on months and run metrics, identify trends\n",
    "Dynamic Network Analysis: For each time segment (months), calculate network metrics (centrality, density, modularity) and observe trends. For example, an increasing trend in the centrality of party nodes or changes in modularity could indicate the party's growing influence or the formation of new clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a41bf099-8c1d-40e9-a177-b0eda78561a8",
   "metadata": {},
   "source": [
    "##### attempt to compare to normal growth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c1bce0-5ba0-402c-9f09-b75ec5ff54a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from datetime import datetime\n",
    "monthly_edges = edgelist.groupby(pd.Grouper(freq='ME'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2636bfbc-e17b-461e-9eaf-f26726f685cb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install python-louvain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76279080-6508-48a0-a526-97f511ce7182",
   "metadata": {},
   "outputs": [],
   "source": [
    "###define functions\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import community as community_louvain\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming 'edgelist' DataFrame is already defined and 'monthly_edges' is created from it\n",
    "# edgelist['datetime'] = pd.to_datetime(edgelist['datetime'])\n",
    "# monthly_edges = edgelist.groupby(pd.Grouper(key='datetime', freq='M'))\n",
    "\n",
    "n_nodes_edges = []\n",
    "\n",
    "# Calculate n_nodes and n_edges for each month\n",
    "for name, group in monthly_edges:\n",
    "    unique_nodes = pd.unique(group[['source', 'target']].values.ravel('K'))\n",
    "    n_nodes = len(unique_nodes)\n",
    "    n_edges = group.shape[0]\n",
    "    n_nodes_edges.append((name, n_nodes, n_edges))\n",
    "\n",
    "n_nodes_edges_filtered = [(name, n_nodes, n_edges) for name, n_nodes, n_edges in n_nodes_edges if n_edges >= 1000]\n",
    "if not n_nodes_edges_filtered[-1][2]:  # Check if the last entry meets your criteria\n",
    "    n_nodes_edges_filtered.pop()\n",
    "\n",
    "def generate_random_network(n_nodes, n_edges):\n",
    "    G_random = nx.Graph()\n",
    "    G_random.add_nodes_from(range(n_nodes))\n",
    "    \n",
    "    while G_random.number_of_edges() < n_edges:\n",
    "        node_pair = np.random.choice(n_nodes, 2, replace=False)\n",
    "        if not G_random.has_edge(*node_pair):\n",
    "            G_random.add_edge(*node_pair)\n",
    "    \n",
    "    return G_random\n",
    "\n",
    "def calculate_average_degree_centrality(G):\n",
    "    degree_centrality = nx.degree_centrality(G)\n",
    "    average_centrality = sum(degree_centrality.values()) / len(degree_centrality)\n",
    "    return average_centrality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166244b3-3f09-4e31-94e0-b6e77c77ed36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "# Assuming generate_random_network and calculate_average_degree_centrality are defined\n",
    "metrics_list = []\n",
    "\n",
    "# Assuming n_nodes_edges_filtered, monthly_edges_list, and monthly_values are already defined\n",
    "for ((name, group), edge_count), (_, n_nodes, n_edges) in zip(zip(monthly_edges_list, monthly_values), n_nodes_edges_filtered):\n",
    "    if edge_count >= 1000:  # Apply the threshold\n",
    "        # Generate a random network with the same n_nodes and n_edges\n",
    "        G_random = generate_random_network(n_nodes, n_edges)\n",
    "        \n",
    "        # Calculate the average degree centrality of the random network\n",
    "        avg_degree_centrality_random = calculate_average_degree_centrality(G_random)\n",
    "        \n",
    "        # Generate the actual network graph from the group\n",
    "        G_actual = nx.from_pandas_edgelist(group, 'source', 'target')\n",
    "        \n",
    "        # Calculate average degree centrality for the actual network\n",
    "        avg_degree_centrality_actual = calculate_average_degree_centrality(G_actual)\n",
    "        \n",
    "        # Calculate density for the actual network\n",
    "        density = nx.density(G_actual)\n",
    "        \n",
    "        # Extract centrality for specified party nodes\n",
    "        degree_centrality = nx.degree_centrality(G_actual)\n",
    "        party_nodes = [\"agfriedendiebasis\", \"die_basis_funkt\", \"diebasisnrwfunkt\"]\n",
    "        party_centrality = {node: degree_centrality.get(node, None) for node in party_nodes}\n",
    "        \n",
    "        # Store metrics, including both random and actual network centrality measures\n",
    "        metrics_list.append({\n",
    "            'month': name.strftime('%Y-%m'),\n",
    "            'density': density,\n",
    "            'avg_degree_centrality_random': avg_degree_centrality_random,\n",
    "            'avg_degree_centrality_actual': avg_degree_centrality_actual,\n",
    "            'party_centrality': party_centrality  # Consider how you want to represent this data\n",
    "        })\n",
    "\n",
    "# Convert metrics list to DataFrame for analysis\n",
    "metrics_df = pd.DataFrame(metrics_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e433a143-9db7-40c7-a354-8230d26b2207",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming metrics_df is your DataFrame and it's already populated with the necessary data\n",
    "\n",
    "# Ensure 'month' is in datetime format for plotting\n",
    "metrics_df['month'] = pd.to_datetime(metrics_df['month'])\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot average degree centrality for random networks\n",
    "plt.plot(metrics_df['month'], metrics_df['avg_degree_centrality_random'], label='Random Network', marker='o', linestyle='-', color='skyblue')\n",
    "\n",
    "# Plot average degree centrality for actual networks\n",
    "plt.plot(metrics_df['month'], metrics_df['avg_degree_centrality_real'], label='Actual Network', marker='x', linestyle='-', color='darkblue')\n",
    "\n",
    "plt.title('Average Degree Centrality Over Time')\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Average Degree Centrality')\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()  # Adjust layout to not cut off labels\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29438ba-ed48-426a-bced-ebcd6bfa4529",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"hi\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "396fb3f4-8228-4035-8699-a20566701a7b",
   "metadata": {},
   "source": [
    "### forgot what this is below its a bit adjusted, perhaps for average growth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6ff48f-154c-4d3b-97d1-b1010dcab03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plotting trends\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(metrics_df['month'], metrics_df['average_adjusted_degree_centrality'], label='average_adjusted_degree_centrality')\n",
    "plt.plot(metrics_df['month'], metrics_df['density'], label='Density')\n",
    "# plt.plot(metrics_df['month'], metrics_df['modularity'], label='Modularity')  # Uncomment when modularity is calculated\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Metric Value')\n",
    "plt.title('Network Metrics Over Time')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dfb6b34-e9cc-476f-87e8-b1de178a16bd",
   "metadata": {},
   "source": [
    "##### here is the actual without adjustment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac03d105-a2c0-4b6c-acc0-851a89df88ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "metrics_list = []\n",
    "\n",
    "for (name, group), edge_count in zip(monthly_edges_list, monthly_values):\n",
    "    if edge_count >= 1000:  # Apply the threshold\n",
    "        G = nx.from_pandas_edgelist(group, 'source', 'target')\n",
    "        \n",
    "        # Calculate density\n",
    "        density = nx.density(G)\n",
    "        \n",
    "        # Calculate degree centrality and normalized degree centrality\n",
    "        degree_centrality = nx.degree_centrality(G)\n",
    "        \n",
    "        adjusted_degree_centrality = {node: centrality * growth_factor for node, centrality in degree_centrality.items()}\n",
    "        \n",
    "        # Calculate average adjusted degree centrality\n",
    "        average_adjusted_degree_centrality = sum(adjusted_degree_centrality.values()) / len(adjusted_degree_centrality) if adjusted_degree_centrality else None\n",
    "        \n",
    "        # Extract centrality for specified party nodes\n",
    "        party_nodes = [\"agfriedendiebasis\", \"die_basis_funkt\", \"diebasisnrwfunkt\"]\n",
    "        party_centrality = {node: degree_centrality.get(node, None) for node in party_nodes}\n",
    "        \n",
    "        # Store metrics\n",
    "        metrics_list.append({\n",
    "            'month': name.strftime('%Y-%m'),\n",
    "            'density': density,\n",
    "            'modularity': modularity,\n",
    "            'party_centrality': party_centrality,\n",
    "            'average_adjusted_degree_centrality': average_adjusted_degree_centrality,\n",
    "        })\n",
    "\n",
    "# Convert metrics list to DataFrame for analysis\n",
    "metrics_df = pd.DataFrame(metrics_list)\n",
    "\n",
    "print(\"Analysis Complete\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07be9d21-0684-420a-87a2-4e3b3e10c276",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plotting trends\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(metrics_df['month'], metrics_df['average_adjusted_degree_centrality'], label='average_adjusted_degree_centrality')\n",
    "plt.plot(metrics_df['month'], metrics_df['density'], label='Density')\n",
    "# plt.plot(metrics_df['month'], metrics_df['modularity'], label='Modularity')  # Uncomment when modularity is calculated\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Metric Value')\n",
    "plt.title('Network Metrics Over Time')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650b8ae4-c8c8-4105-9e2c-a428efdd6fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Sample Data: Replace with your actual data\n",
    "monthly_values = [1, 0, 0, 0, 1, 1, 1, 2, 2, 14, 23, 44, 62, 188, 222, 277, 382, 415, 348, 350, 824, 805, 504, 892, 1130, 3630, 5029, 7029, 9098, 10132, 10278, 9747, 11064, 11963, 11246, 11790, 10518, 11854, 12090, 12633, 12324, 11444, 10873, 10693, 13414, 13994, 14908, 16359, 14797, 14853, 15448, 16003, 16016, 17713, 17824, 22552, 25226, 25338, 21483, 22916, 23656, 28930, 27644, 29069, 28057, 28888, 28148, 27562, 30838, 30294, 30440, 33098, 30089, 1810]\n",
    "\n",
    "# Remove the last month due to incomplete data\n",
    "monthly_values = monthly_values[:-1]\n",
    "\n",
    "# Dates for the x-axis\n",
    "dates = pd.date_range(start='2018-02-28', periods=len(monthly_values), freq='M')\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(15, 6))\n",
    "plt.plot(dates, monthly_values, marker='o', linestyle='-', color='blue')\n",
    "plt.axvline(x=pd.Timestamp('2020-06-26'), color='red', linestyle='--', label='First Party Chat')\n",
    "plt.title('Monthly Edge Counts with Party Formation')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Monthly Edge Counts')\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d081689-04bb-4a5d-a8ee-eea161dcabf2",
   "metadata": {},
   "source": [
    "### step 4:  Comparing Networks With and Without Party Chats\n",
    "Creating two versions of the network—one including party chats and one excluding them—can help isolate the effect of the party on the network.\n",
    "\n",
    "Network Construction: Construct two networks from your dataset: one network includes all edges (with party chats), and the other excludes edges involving party chats.\n",
    "\n",
    "Network Comparison: Analyze and compare key network metrics between the two networks. Metrics to consider include:\n",
    "\n",
    "Network Density: A higher density in the network including party chats could indicate the party contributes significantly to network cohesion.\n",
    "Clustering Coefficient: Differences in the clustering coefficient can reveal changes in network tightness and community structure with the inclusion of party chats.\n",
    "Centrality Distribution: Comparing centrality distributions can help identify if the party nodes serve as critical connectors or hubs in the network.\n",
    "Community Structure: Use community detection algorithms to compare the community structures of the two networks. Significant differences may suggest the party's role in forming or disrupting communication clusters"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
